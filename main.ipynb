{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16877aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name : Manahil Sarwar\n",
    "#Section : AI-K\n",
    "#Roll No : 21I-0293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33a30e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ba681a-9d73-4195-8f52-20b2305e99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation and Loading\n",
    "class SketchFaceDataset(Dataset):\n",
    "    def __init__(self,base_dir,phase='train',transform=None):\n",
    "        self.sketch_dir=os.path.join(base_dir,phase,'sketches')\n",
    "        self.original_dir=os.path.join(base_dir,phase,'photos')\n",
    "        self.transform=transform\n",
    "        #Get list of sketch files and ensure original files match\n",
    "        self.sketch_files=sorted(os.listdir(self.sketch_dir))\n",
    "        self.original_files=sorted(os.listdir(self.original_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sketch_files)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sketch_path=os.path.join(self.sketch_dir,self.sketch_files[idx])\n",
    "        original_path=os.path.join(self.original_dir,self.original_files[idx])\n",
    "        sketch=Image.open(sketch_path).convert(\"RGB\")\n",
    "        original=Image.open(original_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            sketch=self.transform(sketch)\n",
    "            original=self.transform(original)\n",
    "        return sketch,original\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "#Base directory for the dataset\n",
    "base_dir=r\"C:\\Users\\HP\\Downloads\\data\"\n",
    "\n",
    "#Create datasets for train,val,and test phases\n",
    "train_dataset=SketchFaceDataset(base_dir,phase='train',transform=transform)\n",
    "val_dataset=SketchFaceDataset(base_dir,phase='val',transform=transform)\n",
    "test_dataset=SketchFaceDataset(base_dir,phase='test',transform=transform)\n",
    "\n",
    "#Create dataloaders for each phase\n",
    "train_loader=DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=64,shuffle=False)\n",
    "test_loader=DataLoader(test_dataset,batch_size=64,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca9e0e29-1b23-4544-8421-b535094cfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator Class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.main=nn.Sequential(\n",
    "            nn.ConvTranspose2d(100+3,512,4,1,0,bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512,256,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256,128,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128,64,4,2,1,bias=False),   \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64,3,4,2,1,bias=False),        \n",
    "            nn.Tanh()  \n",
    "        )\n",
    "\n",
    "    def forward(self,noise,sketch):\n",
    "        noise=noise.view(noise.size(0),100,1,1)\n",
    "        sketch_pooled=F.adaptive_avg_pool2d(sketch,(1,1))\n",
    "        combined_input=torch.cat([noise,sketch_pooled],dim=1)\n",
    "        fake_images=self.main(combined_input)\n",
    "        return fake_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c707fefd-be9e-415b-a441-e64f5e0aedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator Class\n",
    "class MinibatchDiscrimination(nn.Module):\n",
    "    def __init__(self,in_features,out_features,num_kernels,kernel_dim):\n",
    "        super(MinibatchDiscrimination,self).__init__()\n",
    "        self.num_kernels=num_kernels\n",
    "        self.out_features=out_features\n",
    "        self.T=nn.Parameter(torch.randn(in_features,num_kernels,kernel_dim))\n",
    "\n",
    "    def forward(self,x):\n",
    "        M=x.mm(self.T.view(x.size(1),-1))\n",
    "        M=M.view(-1,self.num_kernels,M.size(1)//self.num_kernels)\n",
    "        out=[]\n",
    "        for i in range(M.size(0)):\n",
    "            out.append(torch.sum(torch.abs(M[i]-M), dim=2))\n",
    "        \n",
    "        out=torch.stack(out,dim=0)\n",
    "        out=torch.exp(-out)\n",
    "        out_sum=torch.sum(out,dim=1)-1\n",
    "        return torch.cat([x,out_sum],dim=1)\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "       \n",
    "        self.main=nn.Sequential(\n",
    "            nn.Conv2d(6,64,4,2,1,bias=False),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(64,128,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.Conv2d(128,256,4,2,1,bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2,inplace=True)\n",
    "        )\n",
    "        self.fc=nn.Linear(256*8*8,512)\n",
    "        self.minibatch_discriminator=MinibatchDiscrimination(512,512,num_kernels=100,kernel_dim=5)\n",
    "        self.final_layer=nn.Sequential(\n",
    "            nn.Linear(512+100,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self,sketch,image):\n",
    "        combined_input=torch.cat([sketch,image],dim=1)\n",
    "        x=self.main(combined_input)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.fc(x)\n",
    "        x=self.minibatch_discriminator(x)\n",
    "        return self.final_layer(x).view(-1)\n",
    "\n",
    "    def get_features(self,sketch,image):\n",
    "        combined_input=torch.cat([sketch,image],dim=1)\n",
    "        x=self.main(combined_input)\n",
    "        return x.view(x.size(0),-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdd566ac-285d-4862-9b03-b2db74f6957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [10:34<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Loss_D: 0.7686, Loss_G: 1.9608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [10:21<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/15] Loss_D: 0.9256, Loss_G: 2.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [10:24<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/15] Loss_D: 0.8425, Loss_G: 2.5884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [10:30<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/15] Loss_D: 0.7171, Loss_G: 2.3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [10:28<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/15] Loss_D: 0.8764, Loss_G: 3.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [10:15<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/15] Loss_D: 0.7890, Loss_G: 1.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [09:55<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/15] Loss_D: 0.7306, Loss_G: 1.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [09:50<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/15] Loss_D: 0.7540, Loss_G: 2.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [10:04<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15] Loss_D: 0.7395, Loss_G: 1.7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [11:59<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/15] Loss_D: 0.7380, Loss_G: 2.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [12:32<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/15] Loss_D: 0.7280, Loss_G: 1.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [11:11<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/15] Loss_D: 0.6837, Loss_G: 1.8326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [11:21<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/15] Loss_D: 0.6866, Loss_G: 1.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [11:23<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/15] Loss_D: 0.7000, Loss_G: 1.8004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [11:25<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/15] Loss_D: 0.7077, Loss_G: 1.6864\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Initialize generator and discriminator\n",
    "netG=Generator().to(device)\n",
    "netD=Discriminator().to(device)\n",
    "\n",
    "#Loss and optimizer\n",
    "criterion=nn.BCELoss()\n",
    "optimizerD=optim.Adam(netD.parameters(),lr=0.0001,betas=(0.5,0.999))\n",
    "optimizerG=optim.Adam(netG.parameters(),lr=0.00005,betas=(0.5,0.999))\n",
    "\n",
    "#Fixed set of sketches for validation\n",
    "fixed_sketches,_ = next(iter(val_loader))\n",
    "fixed_sketches=fixed_sketches[:64].to(device)\n",
    "vutils.save_image(fixed_sketches,'C:/Users/HP/Downloads/output/sketches.png',normalize=True)\n",
    "fixed_noise=torch.randn(64,100,1,1,device=device)\n",
    "\n",
    "epochs=15\n",
    "real_label=1.0\n",
    "fake_label=0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "    for i,data in enumerate(tqdm(train_loader)):\n",
    "        sketches,real_images=data\n",
    "        sketches,real_images=sketches.to(device),real_images.to(device)\n",
    "        b_size=real_images.size(0)\n",
    "\n",
    "        #Label smoothing for the discriminator\n",
    "        real_label_tensor=torch.full((b_size,),0.9,dtype=torch.float,device=device)  # Smoothed real labels\n",
    "        fake_label_tensor=torch.full((b_size,),0.1,dtype=torch.float,device=device)  # Smoothed fake labels\n",
    "\n",
    "        #Train Discriminator\n",
    "        netD.zero_grad()\n",
    "        #Train with real images\n",
    "        output_real=netD(sketches,real_images).view(-1)\n",
    "        lossD_real=criterion(output_real,real_label_tensor)\n",
    "        lossD_real.backward()\n",
    "\n",
    "        #Generate fake images\n",
    "        noise=torch.randn(b_size,100,1,1,device=device) \n",
    "        fake_images=netG(noise,sketches)\n",
    "        \n",
    "        #Train with fake images\n",
    "        output_fake=netD(sketches,fake_images.detach()).view(-1)\n",
    "        lossD_fake=criterion(output_fake,fake_label_tensor)\n",
    "        lossD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        #Train Generator\n",
    "        netG.zero_grad()\n",
    "        output_gen=netD(sketches,fake_images).view(-1)\n",
    "        lossG=criterion(output_gen,real_label_tensor)\n",
    "\n",
    "        #Feature matching loss: encourage generator to produce diverse outputs\n",
    "        real_features=netD.get_features(sketches,real_images)\n",
    "        fake_features=netD.get_features(sketches,fake_images)\n",
    "        feature_matching_loss=torch.mean(torch.abs(real_features-fake_features))\n",
    "\n",
    "        #Combine standard loss with feature matching loss\n",
    "        total_lossG=lossG+0.1 * feature_matching_loss\n",
    "        total_lossG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}] Loss_D: {(lossD_real + lossD_fake).item():.4f}, Loss_G: {total_lossG.item():.4f}')\n",
    "\n",
    "    #Generated Images on fixed set from Val\n",
    "    with torch.no_grad():\n",
    "        fake=netG(fixed_noise,fixed_sketches)\n",
    "        vutils.save_image(fake,f'C:/Users/HP/Downloads/output/fake_epoch_{epoch+1}.png',normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be4eec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_sketches,_=next(iter(test_loader))\n",
    "fixed_sketches=fixed_sketches[:64].to(device)\n",
    "vutils.save_image(fixed_sketches,'C:/Users/HP/Downloads/output/testsketches.png',normalize=True)\n",
    "#Generated Images on fixed set from Val\n",
    "with torch.no_grad():\n",
    "    netG.eval()\n",
    "    fake=netG(fixed_noise,fixed_sketches)\n",
    "    vutils.save_image(fake,f'C:/Users/HP/Downloads/output/testoutput.png',normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84cf7e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete and models saved.\n"
     ]
    }
   ],
   "source": [
    "#Save the models after training\n",
    "torch.save(netG.state_dict(),'C:/Users/HP/Downloads/output/netG_final.pth')\n",
    "torch.save(netD.state_dict(),'C:/Users/HP/Downloads/output/netD_final.pth')\n",
    "\n",
    "print(\"Training complete and models saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0dff2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
